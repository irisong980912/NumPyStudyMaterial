{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Workshop on Data Manipulation and Visualisation - April 30 2019\n",
    "### Moshe Gabel\n",
    "### (based on the Intermediate R Workshop by Sotirios Damouras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple test cell. \n",
    "\n",
    "This cell both computes a variable `a`, but also shows us the value by just writing it as the last line. Jupyter shows the value of the last expression in the cell.\n",
    "\n",
    "To run a cell, select it and press CTRL+ENTER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the a variable\n",
    "a = 123 + 567\n",
    "# Jupyter will show the value of the last expression in the cell (it should be 690)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sets matplotlib to render images inside the notebook (you wouldn't do this in a Python script) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again, select this cell and press CTRL + ENTER to run it.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready for some tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************\n",
    "## Task Block 1: pandas Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dinesafe data to a DataFrame called dinesafe, and view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe = pd.read_csv('./data/dinesafe.csv')\n",
    "dinesafe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the table above. It looks like the column \"ROW_ID\" is an index. Let's reload the table, but this time we'll let pandas know that there is already an index in the file in the \"ROW_ID\" columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe = pd.read_csv('./data/dinesafe.csv', index_col='ROW_ID')\n",
    "dinesafe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we just assigned to the `dinesafe` variable a second time -- and have therefore overwritten the previous value of `dinesafe`. This follows normal Python behaviour, but may look suprising if you execute notebook cells out of order.  Remember: in practice there is only one `dinesafe` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Get basic statistics for numerical columns (describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might see that Pandas accidentally interpreted some of the ID columns as integers (a numeric types) rather than strings. This can sometimes be a problem, and you can tell `read_csv` how to interpret different columns if you need to. However we will keep it as is for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Confirm the observation above by listing the type (dtype) of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code (replace ???)\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse INSPECTION_DATE as a date and add a column of type datetime.\n",
    "Note how the new date column has type `datetime64` while the original INSPECTION_DATE column is a string (`object`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe['Date'] = pd.to_datetime(dinesafe['INSPECTION_DATE'])\n",
    "dinesafe[['INSPECTION_DATE', 'Date']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: List the first 10 columns using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code (replace ???)\n",
    "???.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use `.loc` to list establishment name, type, and status for rows with IDs 1, 13, and 90497. Hint: remember `.loc` acccepts both lists of rows and columns at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code (replace ???)\n",
    "dinesafe.loc[ ??? , ??? ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to work with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************\n",
    "## Task Block 2: Working With Data\n",
    "\n",
    "You may find the pandas cheat sheet useful: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Write one line to find all distinct establishment types (ESTABLISHMENTTYPE) and count them. You can insert additional cells if you need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code:\n",
    "dinesafe['ESTABLISHMENTTYPE'].???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Find the total number of distinct inspections, by counting unique inspection IDs. Get the series and use the `nunique` aggregator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe['INSPECTION_ID'].???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: what is the average fine levied?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use the `min` and `max` aggregations over INSPECTION_DATE to get the earliest and latest inspection in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???.min(), ???.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many days is that? Since INSPECTION_DATE column is a string, we cannot subtract the max and min. However, we already have a \"Date\" column that is a date. We can use `max()` and `min()` and subtract them!\n",
    "\n",
    "**TASK**: Use the `min` and `max` aggregations over the Date column to compute max - min.\n",
    "This is the period of time covered by the dataset. \n",
    "Store the result in a variable called `time_range`, and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = (dinesafe[???].max() - dinesafe[???].min())\n",
    "time_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: What the total number of fines levied in the dataset? Put this in a variable called `total_fines`, and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fines = ???\n",
    "total_fines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the average fine per day: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fines / time_range.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all inspections that took place on \"2018-08-21\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe[dinesafe['INSPECTION_DATE'] == '2018-08-21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops!\n",
    "This table has a row for every *infraction* found during an inspection, so there are multiple rows per inspection. This is not really what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Find all unique inspections (by INSPECTION_ID) performed on \"2018-08-21\". Show the date, inspection id, and the inspected establishment.\n",
    "\n",
    "Guidance:\n",
    "* Start with the above filter to select all rows with the correct date.\n",
    "* Use `.drop_duplicates(subset=...)` on the DataFrame returned by the previous filter to remove rows which we have already seen. \n",
    "  Think: which column (`subset=...`) should be used to determine duplicates?\n",
    "* One we have the rows we want, we can select the columns that we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe[dinesafe['Date'] == '2018-08-21'].drop_duplicates(subset=???)[[???, ???, ???]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: List the top 5 highest fines for a single infraction.\n",
    "\n",
    "Hint: to sort in descending order, use parameter `ascending=False` to sort in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe.???(by=???, ascending=False).???(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: For this final task in this block, print the average fine levied on each type of infractions by severity.\n",
    "\n",
    "Guidance:\n",
    "* You will need to iterate over all distinct severity values, and then use filtering and aggregation to compute the mean.\n",
    "* `.dropna()` will help you avoid empty severity,\n",
    "* `.unique()` returns a list (Series) of unique values.\n",
    "* You can use Python's `print()` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for severity in ???.dropna().???():\n",
    "    mean_fine = dinesafe[??? == severity][???].???()\n",
    "    print('mean fine for', severity, ':', mean_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will later see a more structured way to do these things, without needing to manually iterate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************\n",
    "## Task Block 3 - Basic Visualization\n",
    "\n",
    "The matplotlib cheat sheet: https://www.datacamp.com/community/blog/python-matplotlib-cheat-sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use matplotlib (not pandas) to plot a histogram of fines across the entire dataset. \n",
    "\n",
    "Guidance: \n",
    "* Make sure to add a label to the X axis using `plt.xlabel`.\n",
    "* You encounter a warning from matplotlib due to missing data (NaNs). Use `.dropna()` on the series (just before plotting) to remove them.\n",
    "* You might see some text above the graphical output, for example \"`Text(0.5, 0, 'Fines')`\". This is the value returned by the last function you called. You can suppress it by adding `;` to the end of the last line in your cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.???(dinesafe[???].dropna())\n",
    "plt.xlabel(???) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: repeat the previous task but use pandas for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe[???].plot.???()\n",
    "plt.xlabel(???) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Show a bar graph with the number of each establishments of every type (ESTABLISHMENTTYPE).\n",
    "\n",
    "Guidance:\n",
    "* In the previous block you wrote a line that computes this as a pandas Series. You just need to plot it with `.plot.bar()`.\n",
    "* The default figure size is not wide enough for all the X labels. Add a parameter to the plotting call: `figsize=(12,6)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe['ESTABLISHMENTTYPE'].???().plot.???(figsize=(12,6)) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many establishment types types, most are not interesting. \n",
    "\n",
    "**TASK**: Use `.head` to only plot the top 5 establishment types \n",
    "\n",
    "Hint: this works because the result of the pandas function that counts values is sorted in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe['ESTABLISHMENTTYPE'].???().head().plot.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use pandas to plot a scatterplot of the LONGITUDE (in X) and LATITUDE (in Y) of all establishments.\n",
    "Avoid drawing multiple points for a single establishment by dropping duplicate ESTABLISHMENT_IDs.\n",
    "\n",
    "Use the parameter `alpha=0.1` when drawing, so that points are transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???.drop_duplicates(subset='ESTABLISHMENT_ID').plot.???(x=???, y=???, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Plot a histogram for the amount of fines for every one of the 4 severity types.\n",
    "\n",
    "Guidance: \n",
    "* Get a list (Series) of all unique severity values, excluding NaN. You've done this before.\n",
    "* Iterate over i = 0,1,2,3 , and for each iteration use `plt.subplot(... , ... ,i+1)` to create and select a subplot. Make sure to use the correct number of rows and columns.\n",
    "* Once a subplot is selected, you can filter the rows and plot the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev = ???.dropna().???()\n",
    "for i in range(4):\n",
    "    plt.subplot(???, ???, i+1)\n",
    "    ???[??? == sev[i]]['AMOUNT_FINED'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can also be done by pandas directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinesafe.hist(column='AMOUNT_FINED', by='SEVERITY')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************\n",
    "## Task Block 4 - Reshaping Data\n",
    "\n",
    "Once gain, the pandas cheat sheet may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Rank (sort) establishment types by descending order of total amount fined.\n",
    "Store the result in a variable called `total_per_type` and examine it.\n",
    "\n",
    "Guidance:\n",
    "1. Group all rows by the type of establishment.\n",
    "2. Take the AMOUNT_FINED column form all groups (you don't need to iterate!), then `sum()` it.\n",
    "3. The previous step yields a series where the index is the establishment type, and the value is the total amount fined across all rows of this type.\n",
    "3. Finally, sort the resulting series in descending order of values (`ascending=False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_type = dinesafe.groupby(???)[???].sum().sort_values(ascending=False)\n",
    "total_per_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot all establishment types with total fines larger than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_per_type[total_per_type > 0].plot.bar() ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now rank establishment types by average amount fined per establishment.\n",
    "We will split this to several parts.\n",
    "\n",
    "We first `groupby` given establishment type, and store the result of `groupy` into a variable `grp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = dinesafe.groupby('ESTABLISHMENTTYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Select the fines column from `grp` and apply the `sum()` aggregation.\n",
    "This will give us the  total fines over all establishments of this type.\n",
    "Store the result in a variable called `total_fines` examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fines = grp[???].sum()\n",
    "total_fines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there are more restaurants than bakeries. We want to average the fine over all *unique* establishments.\n",
    "\n",
    "**TASK**: Given `grp` from before, show the number of unique establishment for each type by selecting the establishment ID column and using the `nunique` aggregator.\n",
    "Store the result in a variable called `n_establishments` and examine the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_establishment = ???\n",
    "n_establishment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to combine the two previous results! Dividing the total fines per establishment type (`total_fines`) by the number of unique establishment of that type (`n_establishment`) will give us the average fine per establishment type, and we can then just sort in descending order.\n",
    "\n",
    "**TASK**: coplete the task: compute the average fine per establishment for each establishment type, then rank establishment type by average fine. You can use the pandas `/` operator to divide series.\n",
    "Store the result in a `rank_by_fine` variable and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_fine = (???).???(ascending=False)\n",
    "rank_by_fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like restaurant are only third place, after food court vendors and supermarkets.\n",
    "\n",
    "Lets visualize this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_fine[rank_by_fine > 0].plot.bar()\n",
    "plt.ylabel('Average fine per establishment in $') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to compute the same thing.\n",
    "\n",
    "For example, we can group by establishment type *and* establishment ID.\n",
    "Summing up the amount fined creates a two-level index with a row for every (establishment type, establishment ID) combination, and the value is the total fine for that establishment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dinesafe.groupby(['ESTABLISHMENTTYPE', 'ESTABLISHMENT_ID'])['AMOUNT_FINED'].sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the total amount of fines for each (establishment type, establishment ID) pair, we can simply average across all establishment IDs in each type. This is done by using `mean()` with `level=0` parameter (if we use `level=1`, it would give the establishment ID level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.mean(level=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this matches previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_by_fine.equals(a.mean(level=0).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another complex task: find the establishment name with the highest non-zero total fine amount for each establishment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 3 columns: establishment type, name, and id and compute sum of fines for each such group.\n",
    "a = dinesafe.groupby(['ESTABLISHMENTTYPE', 'ESTABLISHMENT_NAME', 'ESTABLISHMENT_ID'])['AMOUNT_FINED'].sum()\n",
    "# Only keep rows with fines larger than zero.\n",
    "a = a[a>0]\n",
    "# Use `reset_index()` on the result.\n",
    "# This converts the complex multi-level index to just regular columns.\n",
    "a = a.reset_index()\n",
    "# Group by establishment.\n",
    "grp = a.groupby('ESTABLISHMENTTYPE')\n",
    "# Select the row with top amount fined in each establishment.\n",
    "grp.apply(lambda x: x.nlargest(1, 'AMOUNT_FINED'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********\n",
    "\n",
    "The file \"data/establishments.csv\" contains establishment information (address and neighborhood) for many establishments.\n",
    "We will try to match this information with the dinesafe data.\n",
    "Note that not all inspected establishments are peresent in the file!\n",
    "\n",
    "\n",
    "**TASK**: read the file to to a DataFrame called `est` and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = pd.???('data/establishments.csv')\n",
    "est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: merge (inner join) the dinesafe and establishments tables. You should merge on the ESTABLISHMENT_ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(???, ???, on=???, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because address and establishment names are common to both tables, pandas has renamed them to \"ESTABLISHMENT_NAME_x\" and \"ESTABLISHMENT_NAME_y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use merge with inner join to rank the neighborhoods by the number of \n",
    "\"C - Crucial\" type infractions in restaurants only.\n",
    "\n",
    "Guidance:\n",
    "1. First select only rows with the right severity and establishment type.\n",
    "2. Do a `merge` with the `est` table.\n",
    "3. You now have the information you need. Group by the right column, and count the number of unique inspections using INSPECTION_ID.\n",
    "4. Sort the result in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dinesafe.query('SEVERITY == \"???\" and ESTABLISHMENTTYPE == \"???\"')\n",
    "b = pd.merge(a, ???, on=???, how=???) \n",
    "b.???(???)['INSPECTION_ID'].???().???(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Find which distinct establishment do NOT have neighborhood information. Use filtering and `.isin(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dinesafe.drop_duplicates(subset='???')\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "## Task Block 5 - Advanced Plotting\n",
    "\n",
    "See the Seaborn cheat sheet https://www.datacamp.com/community/blog/seaborn-cheat-sheet-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use Seaborn `sns.scatterplot` to recreate the scatter plot of longitude and latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dinesafe, x=???, y=???, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Repeat, but this type use SEVERITY for color information (`hue='SEVERITY'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Use a bar graph to show the average fine for each severity of infraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=???, kind='bar', x=???, y=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit the data to the most interesting rows: those that belong to a restaurant, food court vendor, or supermarket, and where the fine is more than zero.\n",
    "We will filter the rows and store in a variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dinesafe[dinesafe['ESTABLISHMENTTYPE'].isin(['Restaurant', 'Food Court Vendor', 'Supermarket'])]\n",
    "df = df[df['AMOUNT_FINED'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Do fines change for different establishment type? Make a bar chart for `df` where X is the establishment type, Y is the amount of fines, and the color is the severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.???(data=df, kind=???,\n",
    "            ???='ESTABLISHMENTTYPE', ???='AMOUNT_FINED',\n",
    "            ???='SEVERITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do fines change by neighborhood?\n",
    "Let's draw a box plot for each neighborhood.\n",
    "\n",
    "**Task**: Prepare by joining `df` and `est` to get neighborhood info. Store the result in variable `dfn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = ???\n",
    "dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Draw box plots for every neighborhood in `dfn` using `sns.catplot` with `kind='box'`. Let's put AMOUNT_FINED as X (not Y!) and neighborhood (ESTABLISHMENT_NEIGHBORHOOD) as Y (rather than X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??? ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: This is a little messy. Let's increase the height of the Seaborn plot using `height=9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??? ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, but wouldn't it be nice to order order the boxes by the value of fines?\n",
    "\n",
    "**TASK**: Use `dfn` and `groupby` to sort neighborhoods by the median fine for each neighborhood. Store the result in a variable called `neighborhood_median`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_median = ???\n",
    "neighborhood_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now tell Seaborn to order boxes using the `neighborhood_median` order. Use `neighborhood_median.index` to get the sorted list of neighborhoods.\n",
    "\n",
    "**TASK**: Plot the sorted boxplots per neighborhood. Add a parameter `order=neighborhood_median.index` to show sorted boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last trick: let's produce a map of Toronto neighborhoods.\n",
    "\n",
    "We'll plot the scatterplot again, but this time color points by neighborhood.\n",
    "\n",
    "Notes:\n",
    "* We once again merge dinesafe data with neighborhood information.\n",
    "* We turn off legend since it is too large.\n",
    "* By default, Seaborn marks the edges of markers with white. We set `edgecolor='none` to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=pd.merge(dinesafe, est, on='ESTABLISHMENT_ID', how='inner'),\n",
    "                x='LONGITUDE', y='LATITUDE', hue='ESTABLISHMENT_NEIGHBORHOOD',\n",
    "                alpha=0.5, legend=False, edgecolor='none') ;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
